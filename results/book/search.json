[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Molecular landscape: a new framework for personalized medicine in Breast Cancer.",
    "section": "",
    "text": "These are the scripts and prose used to generate the analysis and images for the manuscript."
  },
  {
    "objectID": "surv_analysis_estrogen.html",
    "href": "surv_analysis_estrogen.html",
    "title": "1  Estrogen receptor status is continuous, not dichotomous",
    "section": "",
    "text": "Currently in the clinics estrogen receptor (ER) status is treated as dichotomous condition. Either a breast cancer (BC) is ER positive (ER+) or ER negative (ER-). The threshold for ER+ cells usually is 1% or 10% of the cells positive in a IHC staining. The idea is that ER+ BC patients will receive endocrine therapy, usually tamoxifen or some aromatase inhibitor, for treatment. The problem is not all patients respond the same to these drugs and they also have different proportions of ER+ cells.\nIn this document we show how leveraging molecular information distinguishes ER+ BC patients and how one should look more carefully on ER status. In order to do this, estrogen related signatures: estrogen response early and late from MSigDB(Subramanian et al. 2005) and \\(SET_{ER/PR}\\)(Sinn et al. 2019), are used to calculate scores for each BC patient. These scores then are used to calculate associations with survival analysis. When performing cox regression, we try to adjust for sensible covariates in order to reduce bias. Even though we are adjusting, it is very difficult to know if a covariate is missing in the regression. Thus, care should be always taken when interpreting these results.\nThis chapter is structure in the following way. First section corresponds to loading the datasets and then filtering them. Estrogen signatures scores are calculated using GSVA (Hänzelmann, Castelo, and Guinney 2013). Given the scores, cox regression can be performed adjusting for clinical variables. After this the Hazard ratios can be computed and interpreted along with their confidence intervals."
  },
  {
    "objectID": "surv_analysis_estrogen.html#loading-and-filtering-the-datasets",
    "href": "surv_analysis_estrogen.html#loading-and-filtering-the-datasets",
    "title": "1  Estrogen receptor status is continuous, not dichotomous",
    "section": "1.1 Loading and filtering the datasets",
    "text": "1.1 Loading and filtering the datasets\nThe preprocessing of the datasets is described in the website below: > https://chronchi.github.io/transcriptomics\nTo check the code used here either click in the code button on the top right part of the page or check the github page (github.com/chronchi/molecular_landscape).\nThe TCGA, METABRIC and SCANB cohorts are used in this section here. They are the biggest cohort of Breast cancer patients in the world. Each datasets has an overall equal distribution of ER+ and ER- patients and similar age distribution."
  },
  {
    "objectID": "surv_analysis_estrogen.html#umap-projection-of-the-datasets",
    "href": "surv_analysis_estrogen.html#umap-projection-of-the-datasets",
    "title": "1  Estrogen receptor status is continuous, not dichotomous",
    "section": "1.2 UMAP projection of the datasets",
    "text": "1.2 UMAP projection of the datasets\nThe plots below show how each patient is different in a molecular sense, and even inside each molecular subtype there are some differences. This indicates how different patients, at least molecularly. We only do the umap of samples that have a PAM50 molecular subtype assigned.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom the plots above we see a distinction of the different molecular subtypes."
  },
  {
    "objectID": "surv_analysis_estrogen.html#calculating-scores",
    "href": "surv_analysis_estrogen.html#calculating-scores",
    "title": "1  Estrogen receptor status is continuous, not dichotomous",
    "section": "1.3 Calculating scores",
    "text": "1.3 Calculating scores\nIn order to calculate the scores, the package msigdb is used to load the hallmark data into R. The \\(SET_{ER/PR}\\) is made of the following genes:\n\n\n\n \n  \n    Affy \n    ID \n    is_target \n  \n \n\n  \n    202089_s_at \n    SLC39A6 \n    yes \n  \n  \n    203438_at \n    STC2 \n    yes \n  \n  \n    204508_s_at \n    CA12 \n    yes \n  \n  \n    205225_at \n    ESR1 \n    yes \n  \n  \n    205380_at \n    PDZK1 \n    yes \n  \n  \n    205440_s_at \n    NPY1R \n    yes \n  \n  \n    205831_at \n    CD2 \n    yes \n  \n  \n    206401_s_at \n    MAPT \n    yes \n  \n  \n    209123_at \n    QDPR \n    yes \n  \n  \n    209309_at \n    AZGP1 \n    yes \n  \n  \n    209459_s_at \n    ABAT \n    yes \n  \n  \n    213245_at \n    ADCY1 \n    yes \n  \n  \n    213539_at \n    CD3D \n    yes \n  \n  \n    214440_at \n    NAT1 \n    yes \n  \n  \n    218398_at \n    MRPS30 \n    yes \n  \n  \n    218976_at \n    DNAJC12 \n    yes \n  \n  \n    219197_s_at \n    SCUBE2 \n    yes \n  \n  \n    222379_at \n    KCNE4 \n    yes \n  \n  \n    200650_s_at \n    LDHA \n    no \n  \n  \n    202961_s_at \n    ATP5J2 \n    no \n  \n  \n    211662_s_at \n    VDAC2 \n    no \n  \n  \n    201623_s_at \n    DARS \n    no \n  \n  \n    205480_s_at \n    UGP2 \n    no \n  \n  \n    217750_s_at \n    UBE2Z \n    no \n  \n  \n    212175_s_at \n    AK2 \n    no \n  \n  \n    212050_at \n    WIPF2 \n    no \n  \n  \n    202631_s_at \n    APPBP2 \n    no \n  \n  \n    202342_s_at \n    TRIM2 \n    no \n  \n\n\n\n\n\nThe first 18 genes are considered to be the target genes, the last 10 genes are the genes used for reference. According to their paper, the score is calculated in the following way:\n\\[\nSET_{ER/PR} = \\sum_{i = 1}^{18} \\frac{T_i}{18} - \\sum_{j=1}^{10}\\frac{R_j}{10} + 2\n\\]\nWhere \\(T_i\\) are the expression levels of target genes and \\(R_j\\) are the expression levels of the reference genes. Here we use GSVA to calculate the scores, even when using their genes.\n\n\n\nBefore we calculate any score, let us check the number of genes available for each pathway in each dataset. This is important, in other to have robust scores, most of the genes should be available in the datasets. We also add signatures of 18 and 200 random genes for control.\n\n\n\n\n\n\n \n  \n      \n    tcga \n    scanb \n    metabric \n  \n \n\n  \n    HALLMARK_ESTROGEN_RESPONSE_EARLY \n    195 \n    192 \n    172 \n  \n  \n    HALLMARK_ESTROGEN_RESPONSE_LATE \n    189 \n    184 \n    177 \n  \n  \n    SET_ERPR \n    18 \n    18 \n    18 \n  \n  \n    random_200 \n    141 \n    115 \n    142 \n  \n  \n    random_18 \n    10 \n    10 \n    12 \n  \n\n\n\n\n\nMost of the genes are available in all datasets. Especially the SET gene set is available in all of them, which is very good. Out of the random 18 subset, only half of genes in average are available.\n\n\n\n\n\n\n\n\n\nFor each dataset one can plot the differences in scores for ER+ and ER- BC patients. This should be already an indication that the scores are meaningful. The next sections shows the results for each dataset individually.\n\n\n\n\nTCGAMETABRICSCANB\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFrom the plots above one can conclude that three different estrogen pathways capture the differences between ER status and also molecular subtypes. There are two plots with random genes for control and we can see that there is no difference between the ER status when using those gene sets.\nAnother way to look at the data is to plot by molecular subtype instead of ER status.\n\nTCGAMETABRICSCANB\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn all cohorts the luminal A and B patients have a similar score. Also the distinction is very clear between the basal and HER2-like patients versus luminal A and B.\nOne question that usually arises when calculating scores from gene sets is if proliferation associated genes (PAG) are driving the distinctions. These signatures are highly curated and they have close or no PAGs. Therefore, the scores are not affected by PAGs and they really reflect the biology.\nIn the next section we will show how these scores are also prognostic for ER+ BC patients."
  },
  {
    "objectID": "surv_analysis_estrogen.html#survival-analysis",
    "href": "surv_analysis_estrogen.html#survival-analysis",
    "title": "1  Estrogen receptor status is continuous, not dichotomous",
    "section": "1.4 Survival analysis",
    "text": "1.4 Survival analysis\nSince the scores are continuous variables and they are already scaled due to the output of GSVA, cox regression (Cox 1972) can be used. The advantages of using cox regression is that one can control for other variables. You might ask, why should one control for clinical variables? One of the reasons is because the data being dealt here is observational data. There are several confounders, for example, a score might be up because patients with a higher tumor grade have higher expression of some genes. Thus the score is confounded by the tumor grade and the interpretation changes.\nThere are limitations still when dealing with observational data. A strong hypothesis for performing survival analysis with observational data is that we have measured all the confounder variables. This is pretty strong and in practice we never know if a confounder is missing or not. For a more thorough overview of the causal framework for observational data, check the books (Gelman, Hill, and Vehtari 2020; McElreath 2020).\nAll the cohorts have a different set of clinical variables available. Therefore, the regression will be done by adjusting a different set of variables. Below is the description of the variables used for each cohort.11 This webpage explains with more details the different tumor stages and how BC are classified.\n\nAge: age is one of the most important factors to adjust, specially in breast cancer. This covariate is used for all cohorts.\nNPI: the Nottingham prognostic index scores each tumor based on tumor grade, tumor size and number of lymph nodes. Only METABRIC has this information.\nTumor Size: as name describes. Only SCANB has this information.\nTumor Stage: tumors are usually described in terms of stage, it reflects the tumor size and location. SCANB and TCGA have this information.\nNode Stage: similar to tumor stage, but encodes the number of lymph nodes where breast cancer cells can be found. SCANB and TCGA have this information.\n\nThus the models we are going to use for the survival analysis of each dataset is shown below.\n\nTCGA: ~ score + age + node_stage + tumor_stage,\nSCANB: ~ score + age + node_stage + tumor_stage,\nMETABRIC: ~ score + age + NPI,\n\nwhere score is one of the scores calculated earlier with GSVA. Note here that since each node stage and tumor stage have sub classifications they will be grouped together, otherwise there will be too many variables with few points. We will also subselect specific tumor stages for TCGA and SCANB, since there are very few patients with tumor stage 4.\nTo be very specific in the survival analysis, only endocrine treated patients should be used in the analysis, as that is what are interested in. METABRIC and SCANB has this kind of annotation, but TCGA not. So the survival analysis on SCANB and METABRIC will be performed on endocrine only treated, ER+ BC patients. On TCGA, to mitigate this effect, we subselect only luminal A and B patients, and we keep in mind that they might have been treated with chemotherapy as well. Moreover, in Sweden the guidelines for BC treatment is to use 10% as the threshold for ER status. Therefore, ER+ BC patients used on SCANB are those that are above the 10% threshold.\nThe table below shows the number of patients for each cohort.\n\n\n\n \n  \n    cohort \n    number_patients \n  \n \n\n  \n    TCGA \n    684 \n  \n  \n    SCANB \n    1319 \n  \n  \n    METABRIC \n    938 \n  \n\n\n\n\n\n\n\n\n\n\n\n\n1.4.1 Results\nThe table below shows the results for each analysis performed for a specific term. In order to understand the table the user can filter based on the term, cohort and type of analysis. Since METABRIC has recurrence free survival (RFS) and overall survival (OS), the results for both analysis are presented here.\n\n\n\n\n\n\nThe table above shows that \\(SET_{ER/PR}\\) had a small hazard ratio (< 1) in all 4 analysis performed. Moreover, for all cases where a measure of estrogen signaling was used, the hazard ratio was below 1, indicating that the higher the score, the less likely the patient is to suffer the event in a specific timepoint. This indicates that ER signaling is actually something continuous and not dichotomous.\nThe plot below shows the forest plot of \\(SET_{ER/PR}\\) for all three cohorts.\n\n\n\n\n\nThe hazard ratios are all below 1 and small for \\(SET_{ER/PR}\\). The variability changes depending on the cohort, specially because they have different follow-up times, SCANB being the shortest. TCGA has very few events, but using the 10 to 1 rule of thumb, meaning 10 events for each covariate added, the regression satisfies the rule of thumb."
  },
  {
    "objectID": "surv_analysis_estrogen.html#conclusion",
    "href": "surv_analysis_estrogen.html#conclusion",
    "title": "1  Estrogen receptor status is continuous, not dichotomous",
    "section": "1.5 Conclusion",
    "text": "1.5 Conclusion\nIn this chapter we’ve shown that ER+ BC patients are very distinct from each other, as it can be seen from the umap projections and the subtypes. These patients might respond differently for endocrine therapy as well, and this might depend on the ER signaling, how active it is. Therefore, when deciding a treatment, more care should be taken with ER+ BC patients and check their signaling scores somehow. The \\(SET_{ER/PR}\\) signature is a good signature showing very good hazard ratios across the different cohorts. This signature has also been validated on the clinics for use.\nKnowing the ER signaling for a patient is very important when deciding treatment, but not enough. What could be other alternatives for patients that have low ER signaling and are still considered ER+? Should they use only endocrine therapy or supplement it with something else? In the next chapters we present a framework where we can take a look at a more personalised approach for treatments.\n\n\n\n\n\n\nCox, D. R. 1972. “Regression Models and Life-Tables.” Journal of the Royal Statistical Society: Series B (Methodological) 34 (2): 187–202. https://doi.org/10.1111/j.2517-6161.1972.tb00899.x.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. Regression and Other Stories. Analytical Methods for Social Research. Cambridge, England: Cambridge University Press.\n\n\nHänzelmann, Sonja, Robert Castelo, and Justin Guinney. 2013. “GSVA: Gene Set Variation Analysis for Microarray and RNA-Seq Data.” BMC Bioinformatics 14 (1). https://doi.org/10.1186/1471-2105-14-7.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking. 2nd ed. Chapman & Hall/CRC Texts in Statistical Science. London, England: CRC Press.\n\n\nSinn, Bruno V., Chunxiao Fu, Rosanna Lau, Jennifer Litton, Tsung-Heng Tsai, Rashmi Murthy, Alda Tam, et al. 2019. “SETER/PR: A Robust 18-Gene Predictor for Sensitivity to Endocrine Therapy for Metastatic Breast Cancer.” Npj Breast Cancer 5 (1). https://doi.org/10.1038/s41523-019-0111-0.\n\n\nSubramanian, Aravind, Pablo Tamayo, Vamsi K. Mootha, Sayan Mukherjee, Benjamin L. Ebert, Michael A. Gillette, Amanda Paulovich, et al. 2005. “Gene Set Enrichment Analysis: A Knowledge-Based Approach for Interpreting Genome-Wide Expression Profiles.” Proceedings of the National Academy of Sciences 102 (43): 15545–50. https://doi.org/10.1073/pnas.0506580102."
  },
  {
    "objectID": "pca_merging.html",
    "href": "pca_merging.html",
    "title": "2  A new framework for personalized medicine: integrating",
    "section": "",
    "text": "In the next few chapters we will show a new framework for personalized medicine. This is motivated by the fact that we know already some patients are more sensitive to endocrine therapy than others, but we don’t know what are possible treatments. Moreover, it is very difficult to compare, molecularly, patients among themselves.\nThe PREDICT tool (Wishart et al. 2010) provides a tool for practitioners to calculate survival risks among patients with similar clinical characteristics. This is very important as it shows how to combine data from previous patients to guide further treatments of new patients. However, no additional information is given, such as alternative pathways to target or what might be different from other patients.\nOther tools that help in the clinics are the molecular signatures developed by companies (Wallden et al. 2015; Vijver et al. 2002; Paik et al. 2004). These signatures are intended to be used with ER+ BC patients and depending on the tool, on node negative, post-menopausal women. Based on the set of genes, a risk score is assigned or each patient. The score means if a patient would benefit from additional chemotherapy besides the usual endocrine therapy received for either 5 or 10 years. They also lack the additional information of what are possible pathways involved and alternative treatments beside chemotherapy.\nThere are a few challenges to overcome pathway analysis for patients individually and how to compare patients molecularly. There is no tool that allows to integrate patients in a continuous way. Usually integration is a one step procedure and cannot be updated. The usual tools are (Risso et al. 2014; Zhang, Parmigiani, and Johnson 2020; Fei et al. 2018) and they do not provide batch effect removal for new samples. The only way is to re-run the procedure together with the new sample. The problem of doing this is usually you don’t have enough samples to estimate batch effects across groups and therefore correct it.\nThis chapter show how to perform PCA projection using samples from different datasets and how new samples can be introduced without retraining of the PCA. We first introduce the notion of a new normalization that depends on housekeeping genes. After using this new normalization, we proceed with PCA on a subset of two cohorts using the 1000 most variable genes. We then validate the integration with new samples from a completely different cohort."
  },
  {
    "objectID": "pca_merging.html#transcriptomics-and-qpcr-normalization",
    "href": "pca_merging.html#transcriptomics-and-qpcr-normalization",
    "title": "2  A new framework for personalized medicine: integrating",
    "section": "2.1 Transcriptomics and qPCR normalization",
    "text": "2.1 Transcriptomics and qPCR normalization\nIn this first step we introduce a new normalization. The rational is that we need a normalization procedure that is applied in a single sample only, similar to logCPM, but that can be applied to microarray too. In this case, given a set of samples, we start by ranking the genes in each sample. We then normalize the ranking to be between 0 and 1, i.e., we divide by the total number of genes available in that sample. Then, given a list of 50 stable genes across cancer (Bhuva, Cursons, and Davis 2020), we calculate the average ranking of these genes in the sample and then for each gene in the sample we divide by this average.\n\n2.1.1 Selecting stable genes\n\n\n\n\n\n\nThe first step is to check what number of these 50 genes are available on TCGA and METABRIC, as these datasets will be used for training the PCA projection. The total number of available genes is 44. Table 2.1 shows the name of the genes available in TCGA and METABRIC.\nNow we select the 1000 most variable genes across METABRIC and TCGA. Reducing the number of genes used when calculating the PCA helps in the future. Several publicly available datasets don’t have many genes available, therefore reducing the number of genes increases the chances of using this approach in other datasets.\nMoreover, the use of a large number of genes is used because if some of them are not available. We show in later sections that if some number of stable genes are missing, it will not affect the normalization.\n\n\n\n\n\nFigure 2.1: (Table 2.1) Available stable genes in both TCGA and METABRIC cohorts.\n\n\n\n\n\n2.1.2 Calculating the normalization\nWe will create subset of the summarised experiment objects to save these information. Moreover, since a summarized experiment object is being used, we can save the new normalization in the assays and the average ranking scores of the housekeeping genes in the column data colData. This way it is very easy to retrieve the information for the patients.\n\n\n\nTable 2.2 shows the top 1000 genes along with their standard deviation. The stable genes are also added to the list.\n\n\n\n\n\nFigure 2.2: (Table 2.2) Standard deviation of each gene in each condition and pooled standard deviation.\n\n\n\nOverall we can see that housekeeping genes have very low standard deviation across cohorts, which is good.\n\n\n\n\n\n\nThe histogram below shows the distribution of the average ranking of the housekeeping genes for each sample in each cohort.\n\n\n\n\n\nFigure 2.3: Distribution of the average ranking of the housekeeping genes defined previously for each cohort separately.\n\n\n\n\nThe average ranking are somewhat similar. For the two experiments where there are RNA-seq samples, the distribution is the same. For METABRIC, a microarray experiment, the distribution is shifted a bit below.\nIn the plots below histograms for gene expression of some important genes in breast cancer are plotted.\n\n\n\n\n\nESR1 and TFF1 expressions are divided across ER status, as expected. The proliferation marker CCND1 is also highly expressed in all conditions.\n\n\n2.1.3 Checking robustness with respect of number of houesekeeping genes available\nWhen calculating the normalized data, a total of 44 housekeeping genes were used. Sometimes not all of these genes are available, therefore we will calculate the normalization using random subsets of 44 housekeeping genes with different random sizes. The sets will have a minimum of 20 genes and maximum of 44. The sampling of the set size is obtained by using a uniform distribution. We focus just on TCGA for simplicity.\n\n\n\n\n\n\n\n\n\n\n\nThe plots above show the different distributions given the subsets of housekeeping genes. All the correlation coefficients are close to 1. This means that if a subset of housekeeping genes are missing it is fine, as the others will compensate."
  },
  {
    "objectID": "pca_merging.html#integrating-tcga-and-metabric-using-pca",
    "href": "pca_merging.html#integrating-tcga-and-metabric-using-pca",
    "title": "2  A new framework for personalized medicine: integrating",
    "section": "2.2 Integrating TCGA and METABRIC using PCA",
    "text": "2.2 Integrating TCGA and METABRIC using PCA\nThe next step is creating the framework where we can integrate any patient sample and compare each other, at least spatially. The approach is similar to some sort of unsupervised learning, where no labels or groups are specified, which is something common in algorithms for batch removal. By using PCA in some subset of TCGA and METABRIC, we should learn the idiosyncrasies of the RNA-seq and microarray technologies as well as batch effects general to datasets. Since these two cohorts are big ones, we assume that if there are common batch effects, they are represented on them.\nThe practical steps are: first subselect 1000 samples in total from METABRIC and TCGA. Train PCA using these 1000 samples. Validate the results by projecting the other samples. In the next section we show how robust the approach is when selecting the samples. In the next chapters we validate the projection in unseen cohorts.\nIntegrating as laid out here only uses molecular data, therefore patients might be close to each other but they might have very different clinical features. This should always be kept in mind.\n\n\n\nThe table below shows the molecular characteristics of the patients selected for the PCA training.\n\n\n\n \n  \n    cohort \n    basal \n    claudin-low \n    her2 \n    luma \n    lumb \n    nc \n    normal \n  \n \n\n  \n    metabric \n    83 \n    78 \n    71 \n    215 \n    158 \n    2 \n    41 \n  \n  \n    tcga \n    69 \n    0 \n    29 \n    177 \n    61 \n    0 \n    16 \n  \n\n\n\n\n\n\n\n\n\n\n\nThe following figure shows the embedding of the two datasets together of the 1000 samples used for training. We select several PCs of interest to show how the embedding works.\n\n\n\n\n\nThe first two components correspond to the batch effect. The second component explains the ER status and the two cohorts are well inter mingled. When plotting the second and third components and coloring by the molecular subtype, we see a clear distinction, recapitulating the biology.\n\n\n\n\n\n\nThe plot below shows all the samples from TCGA and cohort projected into the molecular landscape. The samples are mixing well, the only thing is that METABRIC is a bit offset to the left bottom.\n\n\n\n\n\n\n\n\nTo correct the offset, we sum 0.5 in PC2 and 1 in coordinate 3. By doing this, the offset is corrected.\n\n\n\n\n\n\n\n\nBy summing the offset is corrected. The question that remains still is what is causing this offset. Could it be the expression of some genes or it is an offset inherent by the averaging of house keeping genes?\nIn order to check if the integration made sense, it is possible to color by ER status, NPI for METABRIC samples and tumor/node stage for TCGA. To check ER signaling scores, the pathways Estrogen response early/late and \\(SET_{ER/PR}\\) are used to color the projection.\nThe first figure shows the coloring by age.\n\n\n\n\n\nAge seems to be well mixed. Next one is ER status.\n\n\n\n\n\nIt has a very good separation among the different patients.\n\n\n\n\n\nIt looks good, ER+ BC patients have lower NPI, which makes sense.\n\n\n\n\n\nFor both tumor and node stage the samples seem to have mixed well, indicating the projection is not a function of the stages.\nAnd finally the image below shows the color by molecular subtype.\n\n\n\n\n\nThe molecular subtypes are projected as expected, going from left to right there are the basal-like BC patients, going to HER2 and then they are split between luminal A and B. The normal like patients are in the top and closer to the luminal A, reflecting the biology.\nThe next figures show the ER signaling measures coloring the projections.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nIn all cases the mixing is relatively good. For \\(SET_{ER/PR}\\) you have a gradient going from the right to the left and top to bottom, showing again that patients on the far top right probably are those patients with better prognosis.\nThis can actually be validate using survival analysis for the patients by using a combination of PC2 and PC3. In this case the two components were multiplied by each other. Since PC3 is just positive, that means a negative value is in the region of the ER negative patients.\n\nTCGA OSMETABRIC OSMETABRIC RFS\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe score depending on PC2 and PC3 has a hazard ratio smaller than 1, though it is very close. Regardless, it seems that in all cases the score has a small p-value, indicating moderate variability."
  },
  {
    "objectID": "pca_merging.html#the-integration-is-robust-with-respect-of-selection-of-samples",
    "href": "pca_merging.html#the-integration-is-robust-with-respect-of-selection-of-samples",
    "title": "2  A new framework for personalized medicine: integrating",
    "section": "2.3 The integration is robust with respect of selection of samples",
    "text": "2.3 The integration is robust with respect of selection of samples\nThe embedding could be due to the patients selected and samples that are close to each other in one embedding would be far away from them in another embedding. Ten random sets of 1000 patients are sampled and the embedding is calculate. A total of 10 PCA embeddings are obtained.\n\n\n\n\n\n\n\n\n\n\n\nFigure 2.4: Selecting a random set of 1000 patients an rerunning the pipeline to obtain other embeddings. Red color corresponds to the embedding using the new fitted PCA. Blue corresponds to the embedding of the original PCA. Each dot corresponds to a patient.\n\n\n\n\nFigure 2.4 shows that the embedding is invariant for rotation, translation and reflection. Therefore, the subset of samples used for the embedding does not really matter."
  },
  {
    "objectID": "pca_merging.html#normalization-is-necessary-to-reduce-batch-effects-in-other-components",
    "href": "pca_merging.html#normalization-is-necessary-to-reduce-batch-effects-in-other-components",
    "title": "2  A new framework for personalized medicine: integrating",
    "section": "2.4 Normalization is necessary to reduce batch effects in other components",
    "text": "2.4 Normalization is necessary to reduce batch effects in other components\nSince PCA is removing batch effects from the datasets, one could argue it could also remove platform dependent normalization values and therefore one would need to look only at lower principal components. In this section we show that doing the normalization is necessary to get a good integration in the datasets.\nThe idea is similar as before, but instead of performing the qPCR-like normalization on the datasets, one would use the logFPKM values for TCGA and median intensity for microarray. The problem with this kind of approach also includes the fact that only other samples that went through this processing could be used in the pipeline.\n\n\n\n\n\n\n\n\nFigure 2.5: PCA projections colored by different factors and organized by different components. (A) Plot of the first two components colored by cohort. (B) Plot of the first two components colored by ER status. (C) Plot of the second and third components colored by cohort. (D) Plot of the second and third components colored by ER status. (E) Plot of the second and third components colored by PAM50.\n\n\n\n\nFigure 2.5 shows the contrast with the other method including the normalization. Without the normalization, the samples from METABRIC tend to concentrate close to the center, they are not so well mixed. This is to be expected, as they have different scales, specially that the minimum value for METABRIC is around 4.5.\n\n\n\n\n\n\n\n\nFigure 2.6: PC2 and PC3 from all METABRIC and TCGA samples. (A) Embedding using the qPCR-like normalization. (B) Embedding using the original normalization from each dataset.\n\n\n\n\nFigure 2.6 shows side by side the differences when using the qPCR-like normalization and when not using. The left plot is using the qPCR normalization and shows how well the mixing gets, putting samples in the same scale. If the scaling in a sample level is not performed, samples do not mix well.\n\n\n\n\n\n\nBhuva, Dharmesh D, Joseph Cursons, and Melissa J Davis. 2020. “Stable Gene Expression for Normalisation and Single-Sample Scoring.” Nucleic Acids Research 48 (19): e113–13. https://doi.org/10.1093/nar/gkaa802.\n\n\nFei, Teng, Tengjiao Zhang, Weiyang Shi, and Tianwei Yu. 2018. “Mitigating the Adverse Impact of Batch Effects in Sample Pattern Detection.” Edited by Inanc Birol. Bioinformatics 34 (15): 2634–41. https://doi.org/10.1093/bioinformatics/bty117.\n\n\nPaik, Soonmyung, Steven Shak, Gong Tang, Chungyeul Kim, Joffre Baker, Maureen Cronin, Frederick L. Baehner, et al. 2004. “A Multigene Assay to Predict Recurrence of Tamoxifen-Treated, Node-Negative Breast Cancer.” New England Journal of Medicine 351 (27): 2817–26. https://doi.org/10.1056/nejmoa041588.\n\n\nRisso, Davide, John Ngai, Terence P Speed, and Sandrine Dudoit. 2014. “Normalization of RNA-Seq Data Using Factor Analysis of Control Genes or Samples.” Nature Biotechnology 32 (9): 896–902. https://doi.org/10.1038/nbt.2931.\n\n\nVijver, Marc J. van de, Yudong D. He, Laura J. van t Veer, Hongyue Dai, Augustinus A. M. Hart, Dorien W. Voskuil, George J. Schreiber, et al. 2002. “A Gene-Expression Signature as a Predictor of Survival in Breast Cancer.” New England Journal of Medicine 347 (25): 1999–2009. https://doi.org/10.1056/nejmoa021967.\n\n\nWallden, Brett, James Storhoff, Torsten Nielsen, Naeem Dowidar, Carl Schaper, Sean Ferree, Shuzhen Liu, et al. 2015. “Development and Verification of the PAM50-Based Prosigna Breast Cancer Gene Signature Assay.” BMC Medical Genomics 8 (1). https://doi.org/10.1186/s12920-015-0129-6.\n\n\nWishart, Gordon C, Elizabeth M Azzato, David C Greenberg, Jem Rashbass, Olive Kearins, Gill Lawrence, Carlos Caldas, and Paul DP Pharoah. 2010. “PREDICT: A New UK Prognostic Model That Predicts Survival Following Surgery for Invasive Breast Cancer.” Breast Cancer Research 12 (1). https://doi.org/10.1186/bcr2464.\n\n\nZhang, Yuqing, Giovanni Parmigiani, and W Evan Johnson. 2020. “ComBat-Seq: Batch Effect Adjustment for RNA-Seq Count Data.” NAR Genomics and Bioinformatics 2 (3). https://doi.org/10.1093/nargab/lqaa078."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Bhuva, Dharmesh D, Joseph Cursons, and Melissa J Davis. 2020.\n“Stable Gene Expression for Normalisation and Single-Sample\nScoring.” Nucleic Acids Research 48 (19): e113–13. https://doi.org/10.1093/nar/gkaa802.\n\n\nCox, D. R. 1972. “Regression Models and Life-Tables.”\nJournal of the Royal Statistical Society: Series B\n(Methodological) 34 (2): 187–202. https://doi.org/10.1111/j.2517-6161.1972.tb00899.x.\n\n\nFei, Teng, Tengjiao Zhang, Weiyang Shi, and Tianwei Yu. 2018.\n“Mitigating the Adverse Impact of Batch Effects in Sample Pattern\nDetection.” Edited by Inanc Birol. Bioinformatics 34\n(15): 2634–41. https://doi.org/10.1093/bioinformatics/bty117.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2020. Regression and\nOther Stories. Analytical Methods for Social Research. Cambridge,\nEngland: Cambridge University Press.\n\n\nHänzelmann, Sonja, Robert Castelo, and Justin Guinney. 2013.\n“GSVA: Gene Set Variation Analysis for Microarray and\nRNA-Seq Data.” BMC\nBioinformatics 14 (1). https://doi.org/10.1186/1471-2105-14-7.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking. 2nd ed.\nChapman & Hall/CRC Texts in Statistical Science. London, England:\nCRC Press.\n\n\nPaik, Soonmyung, Steven Shak, Gong Tang, Chungyeul Kim, Joffre Baker,\nMaureen Cronin, Frederick L. Baehner, et al. 2004. “A Multigene\nAssay to Predict Recurrence of Tamoxifen-Treated, Node-Negative Breast\nCancer.” New England Journal of Medicine 351 (27):\n2817–26. https://doi.org/10.1056/nejmoa041588.\n\n\nRisso, Davide, John Ngai, Terence P Speed, and Sandrine Dudoit. 2014.\n“Normalization of RNA-Seq Data Using Factor Analysis\nof Control Genes or Samples.” Nature Biotechnology 32\n(9): 896–902. https://doi.org/10.1038/nbt.2931.\n\n\nSinn, Bruno V., Chunxiao Fu, Rosanna Lau, Jennifer Litton, Tsung-Heng\nTsai, Rashmi Murthy, Alda Tam, et al. 2019.\n“SETER/PR: A Robust 18-Gene Predictor\nfor Sensitivity to Endocrine Therapy for Metastatic Breast\nCancer.” Npj Breast Cancer 5 (1). https://doi.org/10.1038/s41523-019-0111-0.\n\n\nSubramanian, Aravind, Pablo Tamayo, Vamsi K. Mootha, Sayan Mukherjee,\nBenjamin L. Ebert, Michael A. Gillette, Amanda Paulovich, et al. 2005.\n“Gene Set Enrichment Analysis: A Knowledge-Based Approach for\nInterpreting Genome-Wide Expression Profiles.” Proceedings of\nthe National Academy of Sciences 102 (43): 15545–50. https://doi.org/10.1073/pnas.0506580102.\n\n\nVijver, Marc J. van de, Yudong D. He, Laura J. van t Veer, Hongyue Dai,\nAugustinus A. M. Hart, Dorien W. Voskuil, George J. Schreiber, et al.\n2002. “A Gene-Expression Signature as a Predictor of Survival in\nBreast Cancer.” New England Journal of Medicine 347\n(25): 1999–2009. https://doi.org/10.1056/nejmoa021967.\n\n\nWallden, Brett, James Storhoff, Torsten Nielsen, Naeem Dowidar, Carl\nSchaper, Sean Ferree, Shuzhen Liu, et al. 2015. “Development and\nVerification of the PAM50-Based Prosigna Breast Cancer Gene\nSignature Assay.” BMC Medical Genomics 8\n(1). https://doi.org/10.1186/s12920-015-0129-6.\n\n\nWishart, Gordon C, Elizabeth M Azzato, David C Greenberg, Jem Rashbass,\nOlive Kearins, Gill Lawrence, Carlos Caldas, and Paul DP Pharoah. 2010.\n“PREDICT: A New UK Prognostic Model That\nPredicts Survival Following Surgery for Invasive Breast Cancer.”\nBreast Cancer Research 12 (1). https://doi.org/10.1186/bcr2464.\n\n\nZhang, Yuqing, Giovanni Parmigiani, and W Evan Johnson. 2020.\n“ComBat-Seq: Batch Effect Adjustment for\nRNA-Seq Count Data.” NAR Genomics\nand Bioinformatics 2 (3). https://doi.org/10.1093/nargab/lqaa078."
  }
]